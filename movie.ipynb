{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "import locale\n",
    "import re\n",
    "from urllib import request\n",
    "import gzip\n",
    "import shutil\n",
    "from multiprocessing.pool import ThreadPool\n",
    "locale.setlocale(locale.LC_TIME, 'de_DE.UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Netflix\n",
    "- go to your account page.\n",
    "- in the desired profile, open the Profiles & Parental Controls setting.\n",
    "- IMPORTANT: ensure the language is set to english!\n",
    "- open Track History.\n",
    "- if the list is not fully displayed, select the Show more button.\n",
    "- Save the file to `NetflixViewingHistory.csv`\n",
    "\n",
    "Next code section:\n",
    "1. Loads data to an dataframe\n",
    "2. converts the string date to a python date format\n",
    "3. the regList identifies any kind of tvSeries marker, which will be used in regexes to determine wether the name is a tvSeries or a movie\n",
    "4. All sufixes in the name e.g. season episode need to be remove for further imdb name mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix = pd.read_csv('NetflixViewingHistory.csv')\n",
    "netflix.columns = ['name', 'date']\n",
    "netflix['date'] = pd.to_datetime(netflix['date'], format='%d/%m/%Y')\n",
    "\n",
    "regList = ['-Staffel ', '– Staffel','- Staffel', ': Season', ': Series', ': Limited Series:', ': Staffel', ': Part', ' Part', ': Vol', ': Volume ', ': Stranger Things ', ': Die komplette 1. Staffel', 'Staffel']\n",
    "combinedMatchList = \".*(\" + \").*|.*(\".join(regList) + \").*\"\n",
    "combinedDelList = \"(\" + \").*|(\".join(regList) + \").*\"\n",
    "\n",
    "netflix['type'] = netflix['name'].apply(lambda x: 'tvseries' if re.match(combinedMatchList, x) is not None else 'movie' )\n",
    "netflix['name'] = netflix['name'].str.replace(combinedDelList, '', regex=True)\n",
    "\n",
    "netflix['service'] = 'Netflix'\n",
    "netflix.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Prime Video\n",
    "- check in to your Amazon Prime Account.\n",
    "- tap on your account.\n",
    "- find Digital Content & Devices.\n",
    "- select Prime Video Settings.\n",
    "- Account & Settings screen opens.\n",
    "- tap on Watch History.\n",
    "- View Watch History.\n",
    "- Manually mark your history and copy & paste it to a txt file.\n",
    "- Save to `PrimeVideoViewingHistoryRaw.csv`\n",
    "\n",
    "Next code section:\n",
    "1. Since Prime Video doesn't provide CSV File but we have Txt File we need to create the columns on our own.\n",
    "2. We can identify each date String and move it to another column, next we can fill the gaps and convert the Strings to Dates.\n",
    "3. As before for Netflix data we can reuse the regexes to detect tVSeries and Movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon = pd.read_table('PrimeVideoViewingHistory.txt',header=None)\n",
    "amazon.columns = ['mixed']\n",
    "\n",
    "# filter out\n",
    "skipLines = ['Folgen aus dem Wiedergabeverlauf löschen', 'Angesehene Folgen', 'Film aus dem Wiedergabeverlauf löschen']\n",
    "amazon = amazon[~amazon['mixed'].isin(skipLines)]\n",
    "\n",
    "# move date\n",
    "amazon['date']=amazon['mixed'][amazon['mixed'].str.match(r'^\\d+. \\S+ \\d+$') == True]\n",
    "amazon.fillna(method='ffill', inplace=True)\n",
    "amazon['date'] = pd.to_datetime(amazon['date'], format='%d. %B %Y')\n",
    "\n",
    "# filter dates in mixed out \n",
    "amazon = amazon[~amazon['mixed'].str.match(r'^\\d+. \\S+ \\d+$')]\n",
    "\n",
    "# replace OV\n",
    "amazon['mixed'] = amazon['mixed'].str.replace('(\\[\\D+\\.\\D+\\])', '', regex=True)\n",
    "\n",
    "# detect tvSeries\n",
    "amazon['type'] = amazon['mixed'].apply(lambda x: 'tvseries' if re.match(combinedMatchList, x) is not None else 'movie' )\n",
    "amazon['name'] = amazon['mixed'].str.replace(combinedDelList, '', regex=True)\n",
    "\n",
    "# cleanup\n",
    "amazon.drop(['mixed'], inplace=True, axis=1, errors='ignore')\n",
    "amazon['service'] = 'Amazon Prime Video'\n",
    "amazon.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next combine Netflix and Amazon Prime Video dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = netflix.append(amazon, ignore_index=True, sort=True)\n",
    "history[\"name\"] = history[\"name\"].str.lower()\n",
    "history[\"name\"] = history[\"name\"].str.strip()\n",
    "history.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDb Datasets\n",
    "\n",
    "Download  IMDb Datasets and combine it into one dataset from https://www.imdb.com/interfaces/ \n",
    "\n",
    "The IMDB dataframe contains info for each season and episode, since our data doesn't offer all information, we need to drop the duplicate titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\"https://datasets.imdbws.com/title.basics.tsv.gz\"\n",
    "        #,\"https://datasets.imdbws.com/title.episode.tsv.gz\"\n",
    "        ,\"https://datasets.imdbws.com/title.ratings.tsv.gz\"\n",
    "        #,\"https://datasets.imdbws.com/title.akas.tsv.gz\"\n",
    "        #,\"https://datasets.imdbws.com/title.crew.tsv.gz\"\n",
    "        #,\"https://datasets.imdbws.com/title.principals.tsv.gz\"\n",
    "        #,\"https://datasets.imdbws.com/name.basics.tsv.gz\"\n",
    "          ]\n",
    "          \n",
    "def download_url(url):\n",
    "    # Download process\n",
    "    print(\"downloading: \",url)\n",
    "    file_title = re.split(pattern='/', string=url)[-1]\n",
    "    urlrtv = request.urlretrieve(url=url, filename=file_title)\n",
    "    \n",
    "    # for \".tsv\" to \".csv\"\n",
    "    title = re.split(pattern=r'\\.tsv', string=file_title)[0] +\".csv\"\n",
    "    \n",
    "    # Unzip \".gz\" file\n",
    "    with gzip.open(file_title, 'rb') as f_in:\n",
    "        with open(title, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "# parallel fast download\n",
    "results = ThreadPool(5).imap_unordered(download_url, urls)\n",
    "\n",
    "imdb = pd.read_csv('title.basics.csv', sep='\\t', na_values=['\\\\N'], low_memory=False)\n",
    "imdbRatings = pd.read_csv('title.ratings.csv', sep='\\t', na_values=['\\\\N'], low_memory=False)\n",
    "imdb = pd.merge(imdb, imdbRatings, how='left', on='tconst')\n",
    "imdb.drop(['isAdult', 'endYear'], inplace=True, axis=1, errors='ignore')\n",
    "imdb[['startYear']] = imdb[['startYear']].astype(str)\n",
    "imdb[\"primaryTitle\"] = imdb[\"primaryTitle\"].str.lower()\n",
    "\n",
    "# normalize different titleTypes\n",
    "imdb[\"titleType\"] = imdb[\"titleType\"].str.lower()\n",
    "imdb['titleType'] = imdb['titleType'].str.replace('tvsiniseries', 'tvseries')\n",
    "imdb['titleType'] = imdb['titleType'].str.replace('tvminiseries', 'tvseries')\n",
    "imdb['titleType'] = imdb['titleType'].str.replace('short', 'movie')\n",
    "imdb['titleType'] = imdb['titleType'].str.replace('tvmovie', 'movie')\n",
    "imdb['titleType'] = imdb['titleType'].str.replace('tvpilot', 'movie')\n",
    "imdb['titleType'] = imdb['titleType'].str.replace('tvshort', 'movie')\n",
    "imdb['titleType'] = imdb['titleType'].str.replace('tvspecial', 'movie')\n",
    "imdb['titleType'] = imdb['titleType'].str.replace('video', 'movie')\n",
    "imdb['titleType'] = imdb['titleType'].str.replace('videogame', 'movie')\n",
    "imdb['titleType'] = imdb['titleType'].str.replace('moviegame', 'movie')\n",
    "imdb = imdb[~imdb['titleType'].isin(['tvepisode'])]\n",
    "imdb.drop_duplicates(subset=['primaryTitle'], keep='first', inplace=True)\n",
    "imdb.head(4)\n",
    "\n",
    "#imdb.describe()\n",
    "#imdb.boxplot()\n",
    "#imdb.hist()\n",
    "#imdb.info()\n",
    "#imdb.isnull().sum()\n",
    "#imdb.groupby(['titleType']).mean()\n",
    "#imdb[imdb['tconst'].str.strip()=='tt3556944']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a high mapping quality, we don't search only by name, but name and type combination. That should catch most cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.merge(history, imdb, how='left', left_on=['name', 'type'], right_on=['primaryTitle', 'titleType'])\n",
    "history.drop(['tconst', 'titleType', 'primaryTitle', 'originalTitle', 'startYear', 'runtimeMinutes'], inplace=True, axis=1, errors='ignore')\n",
    "history.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb.to_csv('imdb.zip', index=False, encoding='utf-8', compression={'method': 'zip', 'archive_name': 'imdb.csv'})\n",
    "history.to_csv('history.zip', index=False, encoding='utf-8', compression={'method': 'zip', 'archive_name': 'history.csv'})"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
